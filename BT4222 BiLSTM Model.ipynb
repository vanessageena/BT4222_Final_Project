{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize\n",
    "import gensim\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.colors as mcolors\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import word2vec\n",
    "import nltk\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12408\\3685901613.py:2: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  data = pd.read_excel('Amazon.xlsx')\n"
     ]
    }
   ],
   "source": [
    "# Loading of dataset\n",
    "data = pd.read_excel('Amazon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>1797882.0</td>\n",
       "      <td>R3I2DHQBR577SS</td>\n",
       "      <td>B001ANOOOE</td>\n",
       "      <td>2102612.0</td>\n",
       "      <td>The Naked Bee Vitmin C Moisturizing Sunscreen ...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love this, excellent sun block!!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>18381298.0</td>\n",
       "      <td>R1QNE9NQFJC2Y4</td>\n",
       "      <td>B0016J22EQ</td>\n",
       "      <td>106393691.0</td>\n",
       "      <td>Alba Botanica Sunless Tanning Lotion, 4 Ounce</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Thank you Alba Bontanica!</td>\n",
       "      <td>The great thing about this cream is that it do...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>19242472.0</td>\n",
       "      <td>R3LIDG2Q4LJBAO</td>\n",
       "      <td>B00HU6UQAG</td>\n",
       "      <td>375449471.0</td>\n",
       "      <td>Elysee Infusion Skin Therapy Elixir, 2oz.</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great Product, I'm 65 years old and this is al...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>19551372.0</td>\n",
       "      <td>R3KSZHPAEVPEAL</td>\n",
       "      <td>B002HWS7RM</td>\n",
       "      <td>255651889.0</td>\n",
       "      <td>Diane D722 Color, Perm And Conditioner Process...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>GOOD DEAL!</td>\n",
       "      <td>I use them as shower caps &amp; conditioning caps....</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>14802407.0</td>\n",
       "      <td>RAI2OIG50KZ43</td>\n",
       "      <td>B00SM99KWU</td>\n",
       "      <td>116158747.0</td>\n",
       "      <td>Biore UV Aqua Rich Watery Essence SPF50+/PA+++...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>this soaks in quick and provides a nice base f...</td>\n",
       "      <td>This is my go-to daily sunblock. It leaves no ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US    1797882.0  R3I2DHQBR577SS  B001ANOOOE       2102612.0   \n",
       "1          US   18381298.0  R1QNE9NQFJC2Y4  B0016J22EQ     106393691.0   \n",
       "2          US   19242472.0  R3LIDG2Q4LJBAO  B00HU6UQAG     375449471.0   \n",
       "3          US   19551372.0  R3KSZHPAEVPEAL  B002HWS7RM     255651889.0   \n",
       "4          US   14802407.0   RAI2OIG50KZ43  B00SM99KWU     116158747.0   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  The Naked Bee Vitmin C Moisturizing Sunscreen ...           Beauty   \n",
       "1      Alba Botanica Sunless Tanning Lotion, 4 Ounce           Beauty   \n",
       "2          Elysee Infusion Skin Therapy Elixir, 2oz.           Beauty   \n",
       "3  Diane D722 Color, Perm And Conditioner Process...           Beauty   \n",
       "4  Biore UV Aqua Rich Watery Essence SPF50+/PA+++...           Beauty   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0          5.0            0.0          0.0    N                 Y   \n",
       "1          5.0            0.0          0.0    N                 Y   \n",
       "2          5.0            0.0          0.0    N                 Y   \n",
       "3          5.0            0.0          0.0    N                 Y   \n",
       "4          5.0            0.0          0.0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1                          Thank you Alba Bontanica!   \n",
       "2                                         Five Stars   \n",
       "3                                         GOOD DEAL!   \n",
       "4  this soaks in quick and provides a nice base f...   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                   Love this, excellent sun block!!  2015-08-31  \n",
       "1  The great thing about this cream is that it do...  2015-08-31  \n",
       "2  Great Product, I'm 65 years old and this is al...  2015-08-31  \n",
       "3  I use them as shower caps & conditioning caps....  2015-08-31  \n",
       "4  This is my go-to daily sunblock. It leaves no ...  2015-08-31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30014 entries, 0 to 30013\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   marketplace        30009 non-null  object        \n",
      " 1   customer_id        30009 non-null  float64       \n",
      " 2   review_id          30009 non-null  object        \n",
      " 3   product_id         30009 non-null  object        \n",
      " 4   product_parent     30009 non-null  float64       \n",
      " 5   product_title      30014 non-null  object        \n",
      " 6   product_category   30009 non-null  object        \n",
      " 7   star_rating        30009 non-null  float64       \n",
      " 8   helpful_votes      30009 non-null  float64       \n",
      " 9   total_votes        30009 non-null  float64       \n",
      " 10  vine               30009 non-null  object        \n",
      " 11  verified_purchase  30009 non-null  object        \n",
      " 12  review_headline    30007 non-null  object        \n",
      " 13  review_body        30002 non-null  object        \n",
      " 14  review_date        30009 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(5), object(9)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out reviews with zero helpful votes\n",
    "df = data[data['helpful_votes'] > 0]\n",
    "\n",
    "# Filter out rows with nan values\n",
    "df = df.dropna()\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# convert float to int\n",
    "df['star_rating'] = df['star_rating'].astype(int)\n",
    "df['helpful_votes'] = df['helpful_votes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>24655453.0</td>\n",
       "      <td>R2A30ALEGLMCGN</td>\n",
       "      <td>B00SAQ9DZY</td>\n",
       "      <td>292127037.0</td>\n",
       "      <td>12 New, High Quality, Amber 2 ml (5/8 Dram) Gl...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good Product</td>\n",
       "      <td>These are great for small mixtures for EO's, e...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>11257536.0</td>\n",
       "      <td>R6CE3SOIUJGP4</td>\n",
       "      <td>B00PYL8MAA</td>\n",
       "      <td>390030149.0</td>\n",
       "      <td>Proganix Agave Nectar Plus Silica Curling Crea...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Love this cream !</td>\n",
       "      <td>Wish I had discovered this years ago ! Leaves ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>23620123.0</td>\n",
       "      <td>R3I4BQ6654MQNA</td>\n",
       "      <td>B00FWXBLHG</td>\n",
       "      <td>464001209.0</td>\n",
       "      <td>Vintage Lil' Sponge Holder</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Great product, fast delivery</td>\n",
       "      <td>I'm in love with this! It's so unique and fits...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>25564245.0</td>\n",
       "      <td>R3LUPG356F1D40</td>\n",
       "      <td>B003KL8CB0</td>\n",
       "      <td>328680790.0</td>\n",
       "      <td>Jenna Jameson Heartbreaker Perfume parent</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Does not smell cheap!</td>\n",
       "      <td>I was given this product in exchange for a rev...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>22393078.0</td>\n",
       "      <td>R2QRUE9REK8OUC</td>\n",
       "      <td>B00461F4PA</td>\n",
       "      <td>608719013.0</td>\n",
       "      <td>Baby Foot Exfoliant Foot Peel, Lavender Scente...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>23.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Better Than Any Pedi</td>\n",
       "      <td>First off, I'll say I'm skeptical. I've tried ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>US</td>\n",
       "      <td>1856513.0</td>\n",
       "      <td>R1NP7JNUKOQYJR</td>\n",
       "      <td>B0002ARF4C</td>\n",
       "      <td>656652514.0</td>\n",
       "      <td>Lafeber's Premium Daily Diet Pellets for Cocka...</td>\n",
       "      <td>Pet Products</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Fantastic product</td>\n",
       "      <td>Fantastic product. I have been using this bran...</td>\n",
       "      <td>2015-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>US</td>\n",
       "      <td>49358505.0</td>\n",
       "      <td>R1SOYNMVFQY125</td>\n",
       "      <td>B0009YUFMK</td>\n",
       "      <td>238149518.0</td>\n",
       "      <td>Pet Supply Imports Herm Sprenger Chrome Plated...</td>\n",
       "      <td>Pet Products</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>If you are this lazy hire someone else to trai...</td>\n",
       "      <td>These are for people who have no idea how to t...</td>\n",
       "      <td>2015-08-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>US</td>\n",
       "      <td>43339631.0</td>\n",
       "      <td>R3AS69IN0CCBEH</td>\n",
       "      <td>B008CO5IUI</td>\n",
       "      <td>793758338.0</td>\n",
       "      <td>Samsung DW7933LRABB 24\" Black Full Console Dis...</td>\n",
       "      <td>Major Appliances</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>The only good thing was it was quiet</td>\n",
       "      <td>This is my first product review.  My advice is...</td>\n",
       "      <td>2015-07-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>US</td>\n",
       "      <td>13150882.0</td>\n",
       "      <td>R2M3HM87H61ETP</td>\n",
       "      <td>B007A1XG5I</td>\n",
       "      <td>730919193.0</td>\n",
       "      <td>New Chapter Every Woman's One Daily 40 Plus Bo...</td>\n",
       "      <td>Health &amp; Personal Care</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Amazon Prime is the best and most cost effecti...</td>\n",
       "      <td>I have been taking these vitamins on and off f...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>US</td>\n",
       "      <td>13069116.0</td>\n",
       "      <td>R11ANGUQFWEHKG</td>\n",
       "      <td>B01068GCB6</td>\n",
       "      <td>897130913.0</td>\n",
       "      <td>Large Colorful Rainbow Delta Kite with Tail 7+...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Go Fly A Kite</td>\n",
       "      <td>This kite is super cool looking and easy to as...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7509 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0             US   24655453.0  R2A30ALEGLMCGN  B00SAQ9DZY     292127037.0   \n",
       "1             US   11257536.0   R6CE3SOIUJGP4  B00PYL8MAA     390030149.0   \n",
       "2             US   23620123.0  R3I4BQ6654MQNA  B00FWXBLHG     464001209.0   \n",
       "3             US   25564245.0  R3LUPG356F1D40  B003KL8CB0     328680790.0   \n",
       "4             US   22393078.0  R2QRUE9REK8OUC  B00461F4PA     608719013.0   \n",
       "...          ...          ...             ...         ...             ...   \n",
       "7504          US    1856513.0  R1NP7JNUKOQYJR  B0002ARF4C     656652514.0   \n",
       "7505          US   49358505.0  R1SOYNMVFQY125  B0009YUFMK     238149518.0   \n",
       "7506          US   43339631.0  R3AS69IN0CCBEH  B008CO5IUI     793758338.0   \n",
       "7507          US   13150882.0  R2M3HM87H61ETP  B007A1XG5I     730919193.0   \n",
       "7508          US   13069116.0  R11ANGUQFWEHKG  B01068GCB6     897130913.0   \n",
       "\n",
       "                                          product_title  \\\n",
       "0     12 New, High Quality, Amber 2 ml (5/8 Dram) Gl...   \n",
       "1     Proganix Agave Nectar Plus Silica Curling Crea...   \n",
       "2                            Vintage Lil' Sponge Holder   \n",
       "3             Jenna Jameson Heartbreaker Perfume parent   \n",
       "4     Baby Foot Exfoliant Foot Peel, Lavender Scente...   \n",
       "...                                                 ...   \n",
       "7504  Lafeber's Premium Daily Diet Pellets for Cocka...   \n",
       "7505  Pet Supply Imports Herm Sprenger Chrome Plated...   \n",
       "7506  Samsung DW7933LRABB 24\" Black Full Console Dis...   \n",
       "7507  New Chapter Every Woman's One Daily 40 Plus Bo...   \n",
       "7508  Large Colorful Rainbow Delta Kite with Tail 7+...   \n",
       "\n",
       "            product_category  star_rating  helpful_votes  total_votes vine  \\\n",
       "0                     Beauty            4              1          1.0    N   \n",
       "1                     Beauty            4              1          1.0    N   \n",
       "2                     Beauty            5              1          1.0    N   \n",
       "3                     Beauty            5              3          3.0    N   \n",
       "4                     Beauty            5             18         23.0    N   \n",
       "...                      ...          ...            ...          ...  ...   \n",
       "7504            Pet Products            5              2          2.0    N   \n",
       "7505            Pet Products            1              2         15.0    N   \n",
       "7506        Major Appliances            1              3          3.0    N   \n",
       "7507  Health & Personal Care            5              3          4.0    N   \n",
       "7508                  Sports            4              3          3.0    N   \n",
       "\n",
       "     verified_purchase                                    review_headline  \\\n",
       "0                    Y                                       Good Product   \n",
       "1                    N                                  Love this cream !   \n",
       "2                    Y                       Great product, fast delivery   \n",
       "3                    N                              Does not smell cheap!   \n",
       "4                    Y                               Better Than Any Pedi   \n",
       "...                ...                                                ...   \n",
       "7504                 Y                                  Fantastic product   \n",
       "7505                 N  If you are this lazy hire someone else to trai...   \n",
       "7506                 N               The only good thing was it was quiet   \n",
       "7507                 Y  Amazon Prime is the best and most cost effecti...   \n",
       "7508                 N                                      Go Fly A Kite   \n",
       "\n",
       "                                            review_body review_date  \n",
       "0     These are great for small mixtures for EO's, e...  2015-08-31  \n",
       "1     Wish I had discovered this years ago ! Leaves ...  2015-08-31  \n",
       "2     I'm in love with this! It's so unique and fits...  2015-08-31  \n",
       "3     I was given this product in exchange for a rev...  2015-08-31  \n",
       "4     First off, I'll say I'm skeptical. I've tried ...  2015-08-31  \n",
       "...                                                 ...         ...  \n",
       "7504  Fantastic product. I have been using this bran...  2015-08-30  \n",
       "7505  These are for people who have no idea how to t...  2015-08-30  \n",
       "7506  This is my first product review.  My advice is...  2015-07-22  \n",
       "7507  I have been taking these vitamins on and off f...  2015-08-31  \n",
       "7508  This kite is super cool looking and easy to as...  2015-08-31  \n",
       "\n",
       "[7509 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>No of Users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating  No of Users\n",
       "0            5         4125\n",
       "1            1         1345\n",
       "2            4          987\n",
       "3            3          574\n",
       "4            2          478"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review=pd.DataFrame(df.groupby('star_rating').size().sort_values(ascending=False).rename('No of Users').reset_index())\n",
    "review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>These are great for small mixtures for EO's, e...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wish I had discovered this years ago ! Leaves ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm in love with this! It's so unique and fits...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was given this product in exchange for a rev...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off, I'll say I'm skeptical. I've tried ...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>Fantastic product. I have been using this bran...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>These are for people who have no idea how to t...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>This is my first product review.  My advice is...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>I have been taking these vitamins on and off f...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7508</th>\n",
       "      <td>This kite is super cool looking and easy to as...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7509 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_body  star_rating  \\\n",
       "0     These are great for small mixtures for EO's, e...            4   \n",
       "1     Wish I had discovered this years ago ! Leaves ...            4   \n",
       "2     I'm in love with this! It's so unique and fits...            5   \n",
       "3     I was given this product in exchange for a rev...            5   \n",
       "4     First off, I'll say I'm skeptical. I've tried ...            5   \n",
       "...                                                 ...          ...   \n",
       "7504  Fantastic product. I have been using this bran...            5   \n",
       "7505  These are for people who have no idea how to t...            1   \n",
       "7506  This is my first product review.  My advice is...            1   \n",
       "7507  I have been taking these vitamins on and off f...            5   \n",
       "7508  This kite is super cool looking and easy to as...            4   \n",
       "\n",
       "      helpful_votes  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 3  \n",
       "4                18  \n",
       "...             ...  \n",
       "7504              2  \n",
       "7505              2  \n",
       "7506              3  \n",
       "7507              3  \n",
       "7508              3  \n",
       "\n",
       "[7509 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset of data we will be working with to train our model\n",
    "data = df[['review_body','star_rating','helpful_votes']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  2  3  4  5\n",
       "0  0  0  0  1  0\n",
       "1  0  0  0  1  0\n",
       "2  0  0  0  0  1\n",
       "3  0  0  0  0  1\n",
       "4  0  0  0  0  1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(data['star_rating'])\n",
    "dummies.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of text in review_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12408\\3765309073.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review_body'] = data['review_body'].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>these are great for small mixtures for eo's, e...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish i had discovered this years ago ! leaves ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'm in love with this! it's so unique and fits...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was given this product in exchange for a rev...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first off, i'll say i'm skeptical. i've tried ...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating  \\\n",
       "0  these are great for small mixtures for eo's, e...            4   \n",
       "1  wish i had discovered this years ago ! leaves ...            4   \n",
       "2  i'm in love with this! it's so unique and fits...            5   \n",
       "3  i was given this product in exchange for a rev...            5   \n",
       "4  first off, i'll say i'm skeptical. i've tried ...            5   \n",
       "\n",
       "   helpful_votes  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              3  \n",
       "4             18  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert to lowercase\n",
    "data['review_body'] = data['review_body'].str.lower()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12408\\1904549873.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review_body'] = data['review_body'].apply(lambda text: remove_punctuation(text))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>these are great for small mixtures for eos esp...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish i had discovered this years ago  leaves m...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im in love with this its so unique and fits wi...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was given this product in exchange for a rev...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first off ill say im skeptical ive tried tons ...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating  \\\n",
       "0  these are great for small mixtures for eos esp...            4   \n",
       "1  wish i had discovered this years ago  leaves m...            4   \n",
       "2  im in love with this its so unique and fits wi...            5   \n",
       "3  i was given this product in exchange for a rev...            5   \n",
       "4  first off ill say im skeptical ive tried tons ...            5   \n",
       "\n",
       "   helpful_votes  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              3  \n",
       "4             18  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove punctuations\n",
    "\n",
    "import string\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "data['review_body'] = data['review_body'].apply(lambda text: remove_punctuation(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12408\\1673002800.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review_body'] = data['review_body'].apply(lambda text: remove_stopwords(text))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great small mixtures eos especially traveling ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish discovered years ago leaves curles super ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im love unique fits decor beautifully couldnt ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>given product exchange review say wow love per...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first ill say im skeptical ive tried tons prod...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating  \\\n",
       "0  great small mixtures eos especially traveling ...            4   \n",
       "1  wish discovered years ago leaves curles super ...            4   \n",
       "2  im love unique fits decor beautifully couldnt ...            5   \n",
       "3  given product exchange review say wow love per...            5   \n",
       "4  first ill say im skeptical ive tried tons prod...            5   \n",
       "\n",
       "   helpful_votes  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              3  \n",
       "4             18  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removal of Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "data['review_body'] = data['review_body'].apply(lambda text: remove_stopwords(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_12408\\541465091.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['review_body'] = data['review_body'].apply(lambda text: remove_urls(text))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great small mixtures eos especially traveling ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wish discovered years ago leaves curles super ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im love unique fits decor beautifully couldnt ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>given product exchange review say wow love per...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first ill say im skeptical ive tried tons prod...</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body  star_rating  \\\n",
       "0  great small mixtures eos especially traveling ...            4   \n",
       "1  wish discovered years ago leaves curles super ...            4   \n",
       "2  im love unique fits decor beautifully couldnt ...            5   \n",
       "3  given product exchange review say wow love per...            5   \n",
       "4  first ill say im skeptical ive tried tons prod...            5   \n",
       "\n",
       "   helpful_votes  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              3  \n",
       "4             18  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Removal of urls\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "data['review_body'] = data['review_body'].apply(lambda text: remove_urls(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data['review_body'], \n",
    "    dummies, \n",
    "    test_size=0.3, random_state=19\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(word_index, path):\n",
    "    def get_coefs(word, *arr):\n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    def load_embeddings(path):\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            embedding_index = {}\n",
    "            \n",
    "            for line in tqdm(f):\n",
    "                word, arr = get_coefs(*line.strip().split(' '))    \n",
    "                if word in word_index:\n",
    "                    embedding_index[word] = arr\n",
    "            \n",
    "        return embedding_index\n",
    "\n",
    "    embedding_index = load_embeddings(path)\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "    \n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        try:\n",
    "            embedding_matrix[i] = embedding_index[word]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_matrix):\n",
    "    words = Input(shape=(None,))\n",
    "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    " \n",
    "    hidden = concatenate([\n",
    "        GlobalMaxPooling1D()(x),\n",
    "        GlobalAveragePooling1D()(x),\n",
    "    ])\n",
    "    hidden = Dense(512, activation='relu')(hidden)\n",
    "    \n",
    "    result = Dense(5, activation='softmax')(hidden)\n",
    "    \n",
    "    model = Model(inputs=words, outputs=result)\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 375 ms\n",
      "Wall time: 384 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\n",
    "tokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE)\n",
    "tokenizer.fit_on_texts(list(x_train) + list(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1999996it [03:16, 10156.56it/s]\n",
      "100%|██████████| 23148/23148 [00:00<00:00, 446354.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# Requires crawl-300d-2M.vec from https://fasttext.cc/docs/en/english-vectors.html\n",
    "embedding_matrix = build_matrix(tokenizer.word_index, './crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966     ophthalmologist actually recommended makeup re...\n",
       "6162    great item good price opened started cleaning ...\n",
       "7036         cats love prime member get free day delivery\n",
       "6601    seat cover appears well made absolutely love a...\n",
       "382     second foot file tried awful proclaim flexible...\n",
       "                              ...                        \n",
       "5032                                                waste\n",
       "1378         love microwave gives space kitchen con price\n",
       "757     product great previously rechargeable model sh...\n",
       "2670     great look fit finish would definitely recommend\n",
       "5725    bought gag gift actually great stretchy fits s...\n",
       "Name: review_body, Length: 5256, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=512\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_train = pad_sequences(x_train, maxlen=512)\n",
    "x_test = pad_sequences(x_test, maxlen=512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained GloVe (Global Vectors for Word Representation) Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 300)    6944700     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " spatial_dropout1d (SpatialDrop  (None, None, 300)   0           ['embedding[0][0]']              \n",
      " out1D)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, None, 512)    1140736     ['spatial_dropout1d[0][0]']      \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 512)         0           ['bidirectional[0][0]']          \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 512)         0           ['bidirectional[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1024)         0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          524800      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 5)            2565        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,612,801\n",
      "Trainable params: 1,668,101\n",
      "Non-trainable params: 6,944,700\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.2393 - accuracy: 0.5665 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 414s 14s/step - loss: 1.2393 - accuracy: 0.5665 - val_loss: 1.0843 - val_accuracy: 0.6126\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 1.0198 - accuracy: 0.6322 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 431s 15s/step - loss: 1.0198 - accuracy: 0.6322 - val_loss: 0.9692 - val_accuracy: 0.6588\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.9305 - accuracy: 0.6575 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 524s 18s/step - loss: 0.9305 - accuracy: 0.6575 - val_loss: 0.9353 - val_accuracy: 0.6658\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.8721 - accuracy: 0.6790 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 548s 19s/step - loss: 0.8721 - accuracy: 0.6790 - val_loss: 0.9677 - val_accuracy: 0.6430\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.8231 - accuracy: 0.6885 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 560s 19s/step - loss: 0.8231 - accuracy: 0.6885 - val_loss: 0.9134 - val_accuracy: 0.6741\n",
      "Epoch 6/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.7642 - accuracy: 0.7092 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 566s 20s/step - loss: 0.7642 - accuracy: 0.7092 - val_loss: 0.8979 - val_accuracy: 0.6741\n",
      "Epoch 7/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.6871 - accuracy: 0.7396 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 588s 20s/step - loss: 0.6871 - accuracy: 0.7396 - val_loss: 0.9293 - val_accuracy: 0.6791\n",
      "Epoch 8/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.6248 - accuracy: 0.7703 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 567s 20s/step - loss: 0.6248 - accuracy: 0.7703 - val_loss: 0.9500 - val_accuracy: 0.6810\n",
      "Epoch 9/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.7899 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 553s 19s/step - loss: 0.5657 - accuracy: 0.7899 - val_loss: 0.9398 - val_accuracy: 0.6709\n",
      "Epoch 10/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4843 - accuracy: 0.8198 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 560s 19s/step - loss: 0.4843 - accuracy: 0.8198 - val_loss: 1.0141 - val_accuracy: 0.6550\n",
      "Epoch 11/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.4034 - accuracy: 0.8655 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 566s 20s/step - loss: 0.4034 - accuracy: 0.8655 - val_loss: 1.0483 - val_accuracy: 0.6487\n",
      "Epoch 12/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.8869 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 568s 20s/step - loss: 0.3313 - accuracy: 0.8869 - val_loss: 1.0911 - val_accuracy: 0.6766\n",
      "Epoch 13/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2967 - accuracy: 0.8970 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 568s 20s/step - loss: 0.2967 - accuracy: 0.8970 - val_loss: 1.1479 - val_accuracy: 0.6741\n",
      "Epoch 14/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.9269 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 575s 20s/step - loss: 0.2398 - accuracy: 0.9269 - val_loss: 1.1561 - val_accuracy: 0.6493\n",
      "Epoch 15/15\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9492 WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "29/29 [==============================] - 567s 20s/step - loss: 0.1906 - accuracy: 0.9492 - val_loss: 1.2396 - val_accuracy: 0.6493\n"
     ]
    }
   ],
   "source": [
    "model = build_model(embedding_matrix)\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor='val_acc', \n",
    "    verbose=1, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    callbacks=[checkpoint],\n",
    "    epochs=15,\n",
    "    validation_split=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 124s 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.67      0.68       419\n",
      "           2       0.15      0.11      0.13       136\n",
      "           3       0.19      0.24      0.21       148\n",
      "           4       0.28      0.17      0.21       309\n",
      "           5       0.77      0.85      0.81      1241\n",
      "\n",
      "    accuracy                           0.64      2253\n",
      "   macro avg       0.42      0.41      0.41      2253\n",
      "weighted avg       0.61      0.64      0.62      2253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_argmax = np.argmax(y_pred, axis=1) + 1\n",
    "y_test_argmax = np.argmax(y_test.values, axis=1) + 1\n",
    "\n",
    "# print(cm)\n",
    "print(classification_report(y_test_argmax, y_pred_argmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 912ms/step\n",
      "Statement: This product is great! | Sentiment: 5 | Probability: 0.9536995887756348\n",
      "Statement: I don't really like the product | Sentiment: 1 | Probability: 0.5354560017585754\n",
      "Statement: this product is shit | Sentiment: 1 | Probability: 0.4589431583881378\n",
      "Statement: irritated my eyes and didn't work | Sentiment: 1 | Probability: 0.8623155355453491\n",
      "Statement: this product is okay, nothing special | Sentiment: 3 | Probability: 0.4560486376285553\n",
      "Statement: pretty okay product, not much to complain about | Sentiment: 3 | Probability: 0.8185773491859436\n"
     ]
    }
   ],
   "source": [
    "statements = [\"This product is great!\", \"I don't really like the product\",\"this product is shit\",\"irritated my eyes and didn't work\",\"this product is okay, nothing special\", \"pretty okay product, not much to complain about\"]\n",
    "\n",
    "# Convert the input statements to numerical data using the same tokenizer that was used during training\n",
    "sequences = tokenizer.texts_to_sequences(statements)\n",
    "X = pad_sequences(sequences, maxlen=100)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print the predictions\n",
    "for i, statement in enumerate(statements):\n",
    "    listOfSentiments = predictions[i].tolist()\n",
    "    # print(listOfSentiments)\n",
    "    rating = listOfSentiments.index(max(listOfSentiments)) + 1\n",
    "    print(f\"Statement: {statement} | Sentiment: {rating} | Probability: {max(listOfSentiments)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
